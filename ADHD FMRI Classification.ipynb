{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nitrc.org/plugins/mwiki/index.php/neurobureau:AthenaPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root = os.curdir\n",
    "\n",
    "#provide dataset directory here\n",
    "dataset_dir = r\"D:\\All Projects\\ML\\ADHD\\Peking_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\JetBrains\\PyCharm Community Edition 2022.1\\Enviroments\\MachineLearning\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from Code.data_generator import FMRIDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv3D, MaxPool3D, TimeDistributed, Flatten, LSTM, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import load_model\n",
    "\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ DATA WORK ============================\n",
    "\n",
    "#file_num = sys.argv[0]\n",
    "# file_num = \"peking\"\n",
    "\n",
    "# Dataframes\n",
    "model_train_data = pd.read_csv(os.path.join(root, \"Data\\\\training_peking.csv\"))\n",
    "model_val_data = pd.read_csv(os.path.join(root, \"Data\\\\validation_peking.csv\"))\n",
    "\n",
    "# Dictionary of data values\n",
    "partition = {'train': model_train_data['Image'].values, \n",
    "             'validation': model_val_data['Image'].values}\n",
    "\n",
    "# Training Data\n",
    "train_labels = {}\n",
    "for index, row in model_train_data.iterrows():\n",
    "    train_labels[row['Image']] = row['DX']\n",
    "    \n",
    "# Validation Data\n",
    "val_labels = {}\n",
    "for index, row in model_val_data.iterrows():\n",
    "    val_labels[row['Image']] = row['DX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ MODEL META ============================\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 6\n",
    "input_shape=(177,28,28,28,1)\n",
    "\n",
    "train_steps_per_epoch = model_train_data.shape[0] // batch_size\n",
    "validate_steps_per_epoch = model_val_data.shape[0] // batch_size\n",
    "\n",
    "# Generators\n",
    "training_generator = FMRIDataGenerator(partition['train'], train_labels, dataset_dir, batch_size)\n",
    "validation_generator = FMRIDataGenerator(partition['validation'], val_labels, dataset_dir, batch_size)\n",
    "\n",
    "curr_time = f'{datetime.now():%H-%M-%S%z_%m%d%Y}'\n",
    "logger_path = dataset_dir + \"/adhd-fmri-history_cv{num}_{time}.csv\".format(num=file_num,time=curr_time)\n",
    "\n",
    "csv_logger = CSVLogger(logger_path, append=True)\n",
    "\n",
    "callbacks = [csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# ============================ MODEL ARCHITECTURE ============================\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    cnn_lstm_model = Sequential()\n",
    "\n",
    "    cnn_lstm_model.add(TimeDistributed(Conv3D(filters=64,kernel_size=(3,3,3),activation='relu'),\n",
    "                                  input_shape=input_shape, name=\"Input_Conv_Layer\"))\n",
    "\n",
    "    cnn_lstm_model.add(TimeDistributed(MaxPool3D(\n",
    "                                    pool_size=(2, 2, 2),\n",
    "                                    strides=(2, 2, 2),\n",
    "                                    padding='valid'\n",
    "                                    ), name=\"Pool_Layer_1\"))\n",
    "\n",
    "    cnn_lstm_model.add(TimeDistributed(Flatten(), name=\"Flatten_Layer\"))\n",
    "    \n",
    "with tf.device('/cpu:0'):\n",
    "\n",
    "    cnn_lstm_model.add(LSTM(10, dropout = 0.3, recurrent_dropout = 0.3, name=\"LSTM_Layer\"))\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    cnn_lstm_model.add(Dense(1, activation = 'sigmoid', name=\"Output_Dense_Layer\"))\n",
    "\n",
    "    cnn_lstm_model.compile(optimizer=optimizers.Adam(lr=0.0001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model.fit_generator(generator=training_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch, verbose=1, callbacks=callbacks,\n",
    "    validation_data=validation_generator, validation_steps=validate_steps_per_epoch,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model.save('my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model = load_model('my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snwmrda1791543_session_1_rest_1.nii.gz 3\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "[[0.4280245]]\n"
     ]
    }
   ],
   "source": [
    "#PREDICTING A SINGLE FILE\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# filepath for a random nii file\n",
    "nii_file = random.choice(os.listdir(dataset_dir))\n",
    "\n",
    "# printing the nii file\n",
    "print(nii_file, model_train_data[model_train_data['Image'] == nii_file]['DX'].values[0])\n",
    "\n",
    "# Load the NII file using nibabel                        \n",
    "img = nib.load(os.path.join(dataset_dir, nii_file))\n",
    "\n",
    "# Get the image data as a numpy array\n",
    "data = img.get_fdata()\n",
    "\n",
    "# Preprocess the image to match the input shape expected by the model\n",
    "# (e.g., resize, normalize, etc.)\n",
    "preprocessed_data = training_generator.preprocess_image(nii_file)\n",
    "\n",
    "# Reshape the preprocessed data to match the input shape expected by the model\n",
    "reshaped_data = np.reshape(preprocessed_data, input_shape)\n",
    "\n",
    "# Make the prediction using the model\n",
    "prediction = cnn_lstm_model.predict(np.expand_dims(reshaped_data, axis=0))\n",
    "\n",
    "# Process the prediction result as needed\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sfnwmrda2714224_session_1_rest_1.nii.gz 0\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "[[0.34515667]]\n",
      "1.0354700088500977\n",
      "sfnwmrda4095748_session_1_rest_1.nii.gz 1\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "[[0.3039945]]\n",
      "0.9119835197925568\n",
      "sfnwmrda1947991_session_1_rest_1.nii.gz 3\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "[[0.32547817]]\n",
      "0.9764344990253448\n"
     ]
    }
   ],
   "source": [
    "#PREDICTING A MULTIPLE FILE\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# filepath for a random nii file\n",
    "nii_files = random.choices(os.listdir(dataset_dir), k=3)\n",
    "\n",
    "for nii_file in nii_files:\n",
    "    # printing the nii file\n",
    "    print(nii_file, model_train_data[model_train_data['Image'] == nii_file]['DX'].values[0])\n",
    "\n",
    "    # Load the NII file using nibabel                        \n",
    "    img = nib.load(os.path.join(dataset_dir, nii_file))\n",
    "\n",
    "    # Get the image data as a numpy array\n",
    "    data = img.get_fdata()\n",
    "\n",
    "    # Preprocess the image to match the input shape expected by the model\n",
    "    # (e.g., resize, normalize, etc.)\n",
    "    preprocessed_data = training_generator.preprocess_image(nii_file)\n",
    "\n",
    "    # Reshape the preprocessed data to match the input shape expected by the model\n",
    "    reshaped_data = np.reshape(preprocessed_data, input_shape)\n",
    "\n",
    "    # Make the prediction using the model\n",
    "    prediction = cnn_lstm_model.predict(np.expand_dims(reshaped_data, axis=0))\n",
    "\n",
    "    # Process the prediction result as needed\n",
    "    print(prediction)\n",
    "    \n",
    "    prediction = prediction[0][0] * np.max(model_train_data['DX'])\n",
    "    print(prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/a/46216013/9221241\n",
    "# def get_model_memory_usage(batch_size, model):\n",
    "#     import numpy as np\n",
    "#     from keras import backend as K\n",
    "\n",
    "#     shapes_mem_count = 0\n",
    "#     internal_model_mem_count = 0\n",
    "#     for l in model.layers:\n",
    "#         layer_type = l.__class__.__name__\n",
    "#         if layer_type == 'Model':\n",
    "#             internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
    "#         single_layer_mem = 1\n",
    "#         for s in l.output_shape:\n",
    "#             if s is None:\n",
    "#                 continue\n",
    "#             single_layer_mem *= s\n",
    "#         shapes_mem_count += single_layer_mem\n",
    "\n",
    "#     trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "#     non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "#     number_size = 4.0\n",
    "#     if K.floatx() == 'float16':\n",
    "#          number_size = 2.0\n",
    "#     if K.floatx() == 'float64':\n",
    "#          number_size = 8.0\n",
    "\n",
    "#     total_memory = number_size*(batch_size*shapes_mem_count + trainable_count + non_trainable_count)\n",
    "#     gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
    "#     return gbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_Conv_Layer (TimeDist  (None, 177, 26, 26, 26,   1792      \n",
      " ributed)                     64)                                \n",
      "                                                                 \n",
      " Pool_Layer_1 (TimeDistribu  (None, 177, 13, 13, 13,   0         \n",
      " ted)                         64)                                \n",
      "                                                                 \n",
      " Flatten_Layer (TimeDistrib  (None, 177, 140608)       0         \n",
      " uted)                                                           \n",
      "                                                                 \n",
      " LSTM_Layer (LSTM)           (None, 10)                5624760   \n",
      "                                                                 \n",
      " Output_Dense_Layer (Dense)  (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5626563 (21.46 MB)\n",
      "Trainable params: 5626563 (21.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# cnn_lstm_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
